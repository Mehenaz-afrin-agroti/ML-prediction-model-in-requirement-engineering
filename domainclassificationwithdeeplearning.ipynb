{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8234de-a0ce-4d63-b24e-afca59219da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from transformers import BertTokenizer\n",
    "import gensim\n",
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c3f05b-d053-4de3-8139-30975a07118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(\"E:/domain/Synthetic User Stories.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "896a2664-ab79-4437-978e-d60d2e026b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         0\n",
       "3         1\n",
       "4         0\n",
       "         ..\n",
       "12396    37\n",
       "12397    36\n",
       "12398    37\n",
       "12399    36\n",
       "12400    37\n",
       "Name: Target, Length: 12401, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = []\n",
    "for row in dataset.iterrows():\n",
    "    target.append(np.where(dataset[\"Domain\"].unique() == row[1][\"Domain\"])[0][0])\n",
    "dataset[\"Target\"] = target\n",
    "dataset[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed7e15e-0452-493a-a655-16f308b188f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "from transformers import AlbertTokenizer\n",
    "from transformers import DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e1289a-6808-42d8-9dc1-3623d4b0c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainSetFastText():\n",
    "    ft_model = fasttext.load_model(\"fasttext_model.bin\")\n",
    "    traindata = []\n",
    "    for msg in dataset['User Story']:\n",
    "        traindata.append(ft_model.get_sentence_vector(msg))\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata\n",
    "\n",
    "def getTrainSetTFIDF():\n",
    "    countvec = CountVectorizer(max_features=100)\n",
    "    bow = countvec.fit_transform(dataset['User Story']).toarray()\n",
    "    tfidfconverter = TfidfTransformer()\n",
    "    X = tfidfconverter.fit_transform(bow).toarray()\n",
    "    training_data = pd.DataFrame(X)\n",
    "    training_data.columns = training_data.columns.astype(str)\n",
    "    return training_data\n",
    "\n",
    "def getTrainSetBERT():\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokenized_data = tokenizer(dataset['User Story'].tolist(), padding=True, truncation=True, max_length=100)\n",
    "    traindata = []\n",
    "    for msg in tokenized_data['input_ids']:\n",
    "        traindata.append(msg)\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata\n",
    "\n",
    "def getTrainSetRoBERTa():\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    tokenized_data = tokenizer(dataset['User Story'].tolist(), padding=True, truncation=True, max_length=100)\n",
    "    traindata = []\n",
    "    for msg in tokenized_data['input_ids']:\n",
    "        traindata.append(msg)\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata\n",
    "\n",
    "def getTrainSetALBERT():\n",
    "    tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "    tokenized_data = tokenizer(dataset['User Story'].tolist(), padding=True, truncation=True, max_length=100)\n",
    "    traindata = []\n",
    "    for msg in tokenized_data['input_ids']:\n",
    "        traindata.append(msg)\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata\n",
    "\n",
    "def getTrainSetDistilBERT():\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    tokenized_data = tokenizer(dataset['User Story'].tolist(), padding=True, truncation=True, max_length=100)\n",
    "    traindata = []\n",
    "    for msg in tokenized_data['input_ids']:\n",
    "        traindata.append(msg)\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata\n",
    "\n",
    "def getTrainSetWord2Vec():\n",
    "    w2v_model = gensim.models.KeyedVectors.load_word2vec_format('word2vec-google-news-300.bin', binary=True)\n",
    "    traindata = []\n",
    "    for msg in dataset['User Story']:\n",
    "        words = msg.split()\n",
    "        vecs = []\n",
    "        for word in words:\n",
    "            if word in w2v_model:\n",
    "                vecs.append(w2v_model[word][:100])\n",
    "        if vecs:\n",
    "            vec_avg = sum(vecs) / len(vecs)\n",
    "        else:\n",
    "            vec_avg = [0] * 100\n",
    "        traindata.append(vec_avg)\n",
    "\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata\n",
    "\n",
    "def getTrainSetGlove():\n",
    "    glove_vectors = gensim.downloader.load('glove-wiki-gigaword-100')\n",
    "    traindata = []\n",
    "    for msg in dataset['User Story']:\n",
    "        words = msg.split()\n",
    "        vecs = []\n",
    "        for word in words:\n",
    "            if word in glove_vectors:\n",
    "                vecs.append(glove_vectors[word])\n",
    "        if vecs:\n",
    "            vec_avg = sum(vecs) / len(vecs)\n",
    "        else:\n",
    "            vec_avg = [0] * 100\n",
    "        traindata.append(vec_avg)\n",
    "\n",
    "    traindata = pd.DataFrame(traindata)\n",
    "    traindata.columns = traindata.columns.astype(str)\n",
    "    return traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3341bb3-d253-4d71-ab9b-c5d0f363fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/992.0 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 262.1/992.0 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 524.3/992.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 992.0/992.0 kB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa4c4c29-db64-4167-a265-92ba98061ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step\n",
      "Mean Accuracy: 0.153\n",
      "Mean Precision (Macro): 0.104\n",
      "Mean Recall (Macro): 0.154\n",
      "Mean F1-Score (Macro): 0.102\n",
      "Mean Precision (Weighted): 0.105\n",
      "Mean Recall (Weighted): 0.153\n",
      "Mean F1-Score (Weighted): 0.103\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetALBERT()  # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_rnn_model(input_length, vocab_size, num_classes):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128),  # Removed input_length\n",
    "        LSTM(64, return_sequences=True),\n",
    "        LSTM(32),\n",
    "        Dense(num_classes, activation='softmax')  # Use softmax for multiclass classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_rnn_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"LSTM\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5f6d4b2-b0d1-4bd5-93bd-2e5767efa387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step\n",
      "Mean Accuracy: 0.993\n",
      "Mean Precision (Macro): 0.957\n",
      "Mean Recall (Macro): 0.958\n",
      "Mean F1-Score (Macro): 0.957\n",
      "Mean Precision (Weighted): 0.992\n",
      "Mean Recall (Weighted): 0.993\n",
      "Mean F1-Score (Weighted): 0.992\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetALBERT()  # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_bilstm_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        Bidirectional(LSTM(64, return_sequences=True, kernel_initializer=initializer)),  # BiLSTM layer 1\n",
    "        Bidirectional(LSTM(32, kernel_initializer=initializer)),  # BiLSTM layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_bilstm_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"LSTM\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9718bb88-d476-497e-a904-72e6b3d8f7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step\n",
      "Mean Accuracy: 0.990\n",
      "Mean Precision (Macro): 0.954\n",
      "Mean Recall (Macro): 0.955\n",
      "Mean F1-Score (Macro): 0.954\n",
      "Mean Precision (Weighted): 0.989\n",
      "Mean Recall (Weighted): 0.990\n",
      "Mean F1-Score (Weighted): 0.989\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetALBERT()  # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_gru_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        GRU(64, return_sequences=True, kernel_initializer=initializer),  # GRU layer 1\n",
    "        GRU(32, kernel_initializer=initializer),  # GRU layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_gru_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"GRU\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "944f05f0-b2bf-4913-acef-fe0c0bc63b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "Mean Accuracy: 0.994\n",
      "Mean Precision (Macro): 0.958\n",
      "Mean Recall (Macro): 0.959\n",
      "Mean F1-Score (Macro): 0.958\n",
      "Mean Precision (Weighted): 0.993\n",
      "Mean Recall (Weighted): 0.994\n",
      "Mean F1-Score (Weighted): 0.993\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetALBERT()  # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_bigru_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        Bidirectional(GRU(64, return_sequences=True, kernel_initializer=initializer)),  # BiGRU layer 1\n",
    "        Bidirectional(GRU(32, kernel_initializer=initializer)),  # BiGRU layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_bigru_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"GRU\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abeb79df-6009-43cc-9e09-77e83ad24510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "Mean Accuracy: 0.116\n",
      "Mean Precision (Macro): 0.069\n",
      "Mean Recall (Macro): 0.121\n",
      "Mean F1-Score (Macro): 0.063\n",
      "Mean Precision (Weighted): 0.071\n",
      "Mean Recall (Weighted): 0.116\n",
      "Mean F1-Score (Weighted): 0.064\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetALBERT()  # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_lstm_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        LSTM(64, return_sequences=True, kernel_initializer=initializer),  # LSTM layer 1\n",
    "        LSTM(32, kernel_initializer=initializer),  # LSTM layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_lstm_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"GRU\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4709d794-9af2-43d8-b3ce-623ebcd91c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 87ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step\n",
      "Mean Accuracy: 0.993\n",
      "Mean Precision (Macro): 0.959\n",
      "Mean Recall (Macro): 0.960\n",
      "Mean F1-Score (Macro): 0.960\n",
      "Mean Precision (Weighted): 0.992\n",
      "Mean Recall (Weighted): 0.993\n",
      "Mean F1-Score (Weighted): 0.992\n"
     ]
    }
   ],
   "source": [
    "#Bilstm with roberta\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetRoBERTa()  # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_bilstm_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        Bidirectional(LSTM(64, return_sequences=True, kernel_initializer=initializer)),  # BiLSTM layer 1\n",
    "        Bidirectional(LSTM(32, kernel_initializer=initializer)),  # BiLSTM layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_bilstm_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"LSTM\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a42fe7-5b33-445d-8912-2b8778c3253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 98ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step\n",
      "Mean Accuracy: 0.993\n",
      "Mean Precision (Macro): 0.955\n",
      "Mean Recall (Macro): 0.954\n",
      "Mean F1-Score (Macro): 0.954\n",
      "Mean Precision (Weighted): 0.993\n",
      "Mean Recall (Weighted): 0.993\n",
      "Mean F1-Score (Weighted): 0.993\n"
     ]
    }
   ],
   "source": [
    "# Bigru with roberta\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetRoBERTa() # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_bigru_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        Bidirectional(GRU(64, return_sequences=True, kernel_initializer=initializer)),  # BiGRU layer 1\n",
    "        Bidirectional(GRU(32, kernel_initializer=initializer)),  # BiGRU layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_bigru_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"GRU\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520204a4-9478-44ca-94a1-c52266f63138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Mean Accuracy: 0.988\n",
      "Mean Precision (Macro): 0.953\n",
      "Mean Recall (Macro): 0.953\n",
      "Mean F1-Score (Macro): 0.953\n",
      "Mean Precision (Weighted): 0.987\n",
      "Mean Recall (Weighted): 0.988\n",
      "Mean F1-Score (Weighted): 0.988\n"
     ]
    }
   ],
   "source": [
    "# GRU with roberta\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetRoBERTa() # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_gru_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        GRU(64, return_sequences=True, kernel_initializer=initializer),  # GRU layer 1\n",
    "        GRU(32, kernel_initializer=initializer),  # GRU layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_gru_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"GRU\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dba9f1d-9e0d-4f75-830c-41f06141247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\n",
      "Mean Accuracy: 0.994\n",
      "Mean Precision (Macro): 0.958\n",
      "Mean Recall (Macro): 0.959\n",
      "Mean F1-Score (Macro): 0.958\n",
      "Mean Precision (Weighted): 0.993\n",
      "Mean Recall (Weighted): 0.994\n",
      "Mean F1-Score (Weighted): 0.993\n"
     ]
    }
   ],
   "source": [
    "#Bilstm with distilbert\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetDistilBERT()  # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_bilstm_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        Bidirectional(LSTM(64, return_sequences=True, kernel_initializer=initializer)),  # BiLSTM layer 1\n",
    "        Bidirectional(LSTM(32, kernel_initializer=initializer)),  # BiLSTM layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_bilstm_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"LSTM\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bad2a83-1a64-4cdb-bc52-2492389ebac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step\n",
      "Mean Accuracy: 0.994\n",
      "Mean Precision (Macro): 0.958\n",
      "Mean Recall (Macro): 0.959\n",
      "Mean F1-Score (Macro): 0.958\n",
      "Mean Precision (Weighted): 0.993\n",
      "Mean Recall (Weighted): 0.994\n",
      "Mean F1-Score (Weighted): 0.993\n"
     ]
    }
   ],
   "source": [
    "# Bigru with distilbert\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetDistilBERT() # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_bigru_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        Bidirectional(GRU(64, return_sequences=True, kernel_initializer=initializer)),  # BiGRU layer 1\n",
    "        Bidirectional(GRU(32, kernel_initializer=initializer)),  # BiGRU layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_bigru_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"GRU\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7208ba6a-9c8b-45ab-9a69-11aeaaa7f25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "Processing Fold 2 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "Processing Fold 3 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "Processing Fold 4 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
      "Processing Fold 5 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "Processing Fold 6 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "Processing Fold 7 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step\n",
      "Processing Fold 8 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step\n",
      "Processing Fold 9 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
      "Processing Fold 10 ...\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "Mean Accuracy: 0.988\n",
      "Mean Precision (Macro): 0.953\n",
      "Mean Recall (Macro): 0.954\n",
      "Mean F1-Score (Macro): 0.953\n",
      "Mean Precision (Weighted): 0.988\n",
      "Mean Recall (Weighted): 0.988\n",
      "Mean F1-Score (Weighted): 0.988\n"
     ]
    }
   ],
   "source": [
    "# GRU with distilbert\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GRU\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Preparing the DataFrame to store results\n",
    "result = pd.DataFrame(columns=[\"Fold\", \"Model\", \"Accuracy\", \"Precision (Macro)\", \"Recall (Macro)\", \"F1-Score (Macro)\",\n",
    "                               \"Precision (Weighted)\", \"Recall (Weighted)\", \"F1-Score (Weighted)\"], index=np.arange(300))\n",
    "fold = KFold(n_splits=10, random_state=6666, shuffle=True)\n",
    "\n",
    "# Assuming X is preprocessed sequence data, and y is the target labels\n",
    "X = getTrainSetDistilBERT() # Replace with your sequence data processing\n",
    "y = dataset['Target'].values  # Make sure this is your target (multiclass) column\n",
    "counter = 0\n",
    "foldcounter = 1\n",
    "\n",
    "# Define lists to store each metric for mean calculation\n",
    "accuracy_list = []\n",
    "precision_macro_list = []\n",
    "recall_macro_list = []\n",
    "f1_macro_list = []\n",
    "precision_weighted_list = []\n",
    "recall_weighted_list = []\n",
    "f1_weighted_list = []\n",
    "\n",
    "# Define maximum sequence length for padding\n",
    "max_sequence_length = 100  # Set appropriate length based on your data\n",
    "\n",
    "def create_gru_model(input_length, vocab_size, num_classes, learning_rate=0.001, initializer=GlorotUniform()):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size + 1, output_dim=128, embeddings_initializer=initializer),  # Word embedding layer\n",
    "        GRU(64, return_sequences=True, kernel_initializer=initializer),  # GRU layer 1\n",
    "        GRU(32, kernel_initializer=initializer),  # GRU layer 2\n",
    "        Dense(num_classes, activation='softmax', kernel_initializer=initializer)  # Output layer with softmax activation\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)  # Set the optimizer with learning rate\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Find the maximum word index in your data\n",
    "max_word_index = 0\n",
    "for seq in X:\n",
    "    seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "    if seq_int:\n",
    "        max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    print(\"Processing Fold \"+ str(foldcounter) + \" ...\")\n",
    "\n",
    "    # Split data into train and test sets for the current fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Convert y_train and y_test to one-hot encoding (for multiclass classification)\n",
    "    y_train = np.eye(len(np.unique(y)))[y_train]  # One-hot encode labels\n",
    "    y_test = np.eye(len(np.unique(y)))[y_test]  # One-hot encode labels\n",
    "\n",
    "    # Convert X_train and X_test to lists of lists\n",
    "    X_train = X_train.values.tolist()  # Convert DataFrame to list of lists\n",
    "    X_test = X_test.values.tolist()  # Convert DataFrame to list of lists\n",
    "\n",
    "    # Find the maximum word index in the sequences\n",
    "    for seq in X_test:\n",
    "        seq_int = [int(x) for x in seq if str(x).isdigit()]\n",
    "        if seq_int:\n",
    "            max_word_index = max(max_word_index, max(seq_int))\n",
    "\n",
    "    # Add buffer to vocabulary size\n",
    "    max_word_index += 50\n",
    "\n",
    "    # Padding sequences to ensure consistent input shape\n",
    "    X_train_padded = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_test_padded = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_gru_model(input_length=max_sequence_length, vocab_size=max_word_index, num_classes=len(np.unique(y)))\n",
    "    model.fit(X_train_padded, y_train, epochs=50, batch_size=256, verbose=0)\n",
    "\n",
    "    # Make predictions on the test set (get the class with the highest probability)\n",
    "    y_pred_prob = model.predict(X_test_padded)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "    y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot to class labels\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    precision_macro = precision_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    recall_macro = recall_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    f1_macro = f1_score(y_test_labels, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Calculate weighted metrics\n",
    "    precision_weighted = precision_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    recall_weighted = recall_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "    f1_weighted = f1_score(y_test_labels, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Store metrics in lists for mean calculation\n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_macro_list.append(precision_macro)\n",
    "    recall_macro_list.append(recall_macro)\n",
    "    f1_macro_list.append(f1_macro)\n",
    "    precision_weighted_list.append(precision_weighted)\n",
    "    recall_weighted_list.append(recall_weighted)\n",
    "    f1_weighted_list.append(f1_weighted)\n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    result.loc[counter, \"Fold\"] = foldcounter\n",
    "    result.loc[counter, \"Model\"] = \"GRU\"\n",
    "    result.loc[counter, \"Accuracy\"] = round(accuracy, 3)\n",
    "    result.loc[counter, \"Precision (Macro)\"] = round(precision_macro, 3)\n",
    "    result.loc[counter, \"Recall (Macro)\"] = round(recall_macro, 3)\n",
    "    result.loc[counter, \"F1-Score (Macro)\"] = round(f1_macro, 3)\n",
    "    result.loc[counter, \"Precision (Weighted)\"] = round(precision_weighted, 3)\n",
    "    result.loc[counter, \"Recall (Weighted)\"] = round(recall_weighted, 3)\n",
    "    result.loc[counter, \"F1-Score (Weighted)\"] = round(f1_weighted, 3)\n",
    "\n",
    "    counter += 1\n",
    "    foldcounter += 1\n",
    "\n",
    "# Calculate mean values for all metrics\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_precision_macro = np.mean(precision_macro_list)\n",
    "mean_recall_macro = np.mean(recall_macro_list)\n",
    "mean_f1_macro = np.mean(f1_macro_list)\n",
    "mean_precision_weighted = np.mean(precision_weighted_list)\n",
    "mean_recall_weighted = np.mean(recall_weighted_list)\n",
    "mean_f1_weighted = np.mean(f1_weighted_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.3f}\")\n",
    "print(f\"Mean Precision (Macro): {mean_precision_macro:.3f}\")\n",
    "print(f\"Mean Recall (Macro): {mean_recall_macro:.3f}\")\n",
    "print(f\"Mean F1-Score (Macro): {mean_f1_macro:.3f}\")\n",
    "print(f\"Mean Precision (Weighted): {mean_precision_weighted:.3f}\")\n",
    "print(f\"Mean Recall (Weighted): {mean_recall_weighted:.3f}\")\n",
    "print(f\"Mean F1-Score (Weighted): {mean_f1_weighted:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f33eb6-d1ca-42f6-b65d-9af4734b00f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
